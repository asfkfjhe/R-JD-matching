{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/supriya/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load job descriptions from \"job_descriptions.csv\"\n",
    "# job_descriptions_df = pd.read_csv(\"job_descriptions.csv\")\n",
    "# job_descriptions = job_descriptions_df[\"Job Description\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load merged data from \"merged.csv\"\n",
    "# merged_df = pd.read_csv(\"merged.csv\")\n",
    "# if \"Top Skills\" in merged_df.columns:\n",
    "#     resume_skills = merged_df[\"Top Skills\"].fillna('').str.split(',').apply(lambda x: [s.strip() for s in x]).tolist()\n",
    "# elif \"Skills\" in merged_df.columns:\n",
    "#     resume_skills = merged_df[\"Skills\"].fillna('').str.split(',').apply(lambda x: [s.strip() for s in x]).tolist()\n",
    "# else:\n",
    "#     raise ValueError(\"No 'Top Skills' or 'Skills' column found in merged.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load DistilBERT tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to preprocess and get embeddings for text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling\n",
    "    return embeddings.numpy()  # Convert to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Create a DataFrame to store results\n",
    "# results_df = pd.DataFrame(columns=[\"Job Description\", \"Selected Resumes\", \"Similarity Scores\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Iterate through job descriptions\n",
    "# for job_description in tqdm(job_descriptions, desc=\"Processing Job Descriptions\"):\n",
    "#     job_description_embeddings = get_embeddings(job_description)\n",
    "\n",
    "#     top_resumes = []\n",
    "#     top_similarity_scores = []\n",
    "\n",
    "#     # Calculate cosine similarity scores for each resume individually\n",
    "#     for resume_skill in resume_skills:\n",
    "#         resume_embeddings = get_embeddings(' '.join(resume_skill))\n",
    "#         similarity_score = calculate_cosine_similarity(job_description_embeddings, resume_embeddings)\n",
    "#         top_resumes.append(resume_skill)  # Append the skill as a representation of the resume\n",
    "#         top_similarity_scores.append(similarity_score[0][0])\n",
    "\n",
    "#     # Find the top 3 resumes with highest similarity scores\n",
    "#     top_indices = np.argsort(top_similarity_scores)[-3:][::-1]\n",
    "#     top_resumes = [top_resumes[i] for i in top_indices]\n",
    "#     top_similarity_scores = [top_similarity_scores[i] for i in top_indices]\n",
    "\n",
    "#     new_row = {\n",
    "#         \"Job Description\": job_description,\n",
    "#         \"Selected Resumes\": ', '.join([' '.join(resume) for resume in top_resumes]),\n",
    "#         \"Similarity Scores\": ', '.join(map(str, top_similarity_scores))\n",
    "#     }\n",
    "#     results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'company name': ['Google'], 'Job Description': ['We are seeking a skilled Data Scientist to join our team. As a Data Scientist, you will be responsible for interpreting complex data sets to provide actionable insights and solutions. Your role will involve developing algorithms, conducting statistical analysis, and creating predictive models to optimize decision-making processes.'], 'Position Title': ['Data Scientist']}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company name</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Position Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>We are seeking a skilled Data Scientist to joi...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company name                                    Job Description  \\\n",
       "0       Google  We are seeking a skilled Data Scientist to joi...   \n",
       "\n",
       "   Position Title  \n",
       "0  Data Scientist  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = df['Job Description'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are seeking a skilled Data Scientist to join our team. As a Data Scientist, you will be responsible for interpreting complex data sets to provide actionable insights and solutions. Your role will involve developing algorithms, conducting statistical analysis, and creating predictive models to optimize decision-making processes.\n"
     ]
    }
   ],
   "source": [
    "print(jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from PyPDF2 import PdfReader\n",
    "import spacy\n",
    "import re\n",
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_file_path):\n",
    "    try:\n",
    "        reader = PdfReader(pdf_file_path)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", str(e))\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf('Supriya_Resume.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "\n",
    "    return text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_text = preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keybert import KeyBERT\n",
    "# kw_model = KeyBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills_keywords(text):\n",
    "    keyword_extractor = yake.KeywordExtractor()\n",
    "\n",
    "    skill_keywords_extracted = keyword_extractor.extract_keywords(text)\n",
    "\n",
    "    skill_keywords = [keyword for keyword, score in skill_keywords_extracted]\n",
    "\n",
    "    return skill_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyresparser import ResumeParser\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E053] Could not read config file from /home/supriya/anaconda3/lib/python3.11/site-packages/en_core_web_sm/en_core_web_sm-2.3.1/config.cfg",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/supriya/Desktop/R-JD-matching/index.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m ResumeParser(\u001b[39m\"\u001b[39m\u001b[39mSupriya_Resume.pdf\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mget_extracted_data()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyresparser/resume_parser.py:20\u001b[0m, in \u001b[0;36mResumeParser.__init__\u001b[0;34m(self, resume, skills_file, custom_regex)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     15\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     16\u001b[0m     resume,\n\u001b[1;32m     17\u001b[0m     skills_file\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m     custom_regex\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m     19\u001b[0m ):\n\u001b[0;32m---> 20\u001b[0m     nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m     custom_nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(\u001b[39m__file__\u001b[39m)))\n\u001b[1;32m     22\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__skills_file \u001b[39m=\u001b[39m skills_file\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39mload_model(\n\u001b[1;32m     52\u001b[0m         name,\n\u001b[1;32m     53\u001b[0m         vocab\u001b[39m=\u001b[39mvocab,\n\u001b[1;32m     54\u001b[0m         disable\u001b[39m=\u001b[39mdisable,\n\u001b[1;32m     55\u001b[0m         enable\u001b[39m=\u001b[39menable,\n\u001b[1;32m     56\u001b[0m         exclude\u001b[39m=\u001b[39mexclude,\n\u001b[1;32m     57\u001b[0m         config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m     58\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:465\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[39mreturn\u001b[39;00m get_lang_class(name\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mblank:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))()\n\u001b[1;32m    464\u001b[0m \u001b[39mif\u001b[39;00m is_package(name):  \u001b[39m# installed as package\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_package(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[39mif\u001b[39;00m Path(name)\u001b[39m.\u001b[39mexists():  \u001b[39m# path to model data directory\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:501\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[39mname (str): The package name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[39mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(name)\n\u001b[0;32m--> 501\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mload(vocab\u001b[39m=\u001b[39mvocab, disable\u001b[39m=\u001b[39mdisable, enable\u001b[39m=\u001b[39menable, exclude\u001b[39m=\u001b[39mexclude, config\u001b[39m=\u001b[39mconfig)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/en_core_web_sm/__init__.py:12\u001b[0m, in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides):\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_init_py(\u001b[39m__file__\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:682\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_path\u001b[39m.\u001b[39mexists():\n\u001b[1;32m    681\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE052\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mdata_path))\n\u001b[0;32m--> 682\u001b[0m \u001b[39mreturn\u001b[39;00m load_model_from_path(\n\u001b[1;32m    683\u001b[0m     data_path,\n\u001b[1;32m    684\u001b[0m     vocab\u001b[39m=\u001b[39mvocab,\n\u001b[1;32m    685\u001b[0m     meta\u001b[39m=\u001b[39mmeta,\n\u001b[1;32m    686\u001b[0m     disable\u001b[39m=\u001b[39mdisable,\n\u001b[1;32m    687\u001b[0m     enable\u001b[39m=\u001b[39menable,\n\u001b[1;32m    688\u001b[0m     exclude\u001b[39m=\u001b[39mexclude,\n\u001b[1;32m    689\u001b[0m     config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m    690\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:538\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    536\u001b[0m config_path \u001b[39m=\u001b[39m model_path \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mconfig.cfg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    537\u001b[0m overrides \u001b[39m=\u001b[39m dict_to_dot(config, for_overrides\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 538\u001b[0m config \u001b[39m=\u001b[39m load_config(config_path, overrides\u001b[39m=\u001b[39moverrides)\n\u001b[1;32m    539\u001b[0m nlp \u001b[39m=\u001b[39m load_model_from_config(\n\u001b[1;32m    540\u001b[0m     config,\n\u001b[1;32m    541\u001b[0m     vocab\u001b[39m=\u001b[39mvocab,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m     meta\u001b[39m=\u001b[39mmeta,\n\u001b[1;32m    546\u001b[0m )\n\u001b[1;32m    547\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\u001b[39m.\u001b[39mfrom_disk(model_path, exclude\u001b[39m=\u001b[39mexclude, overrides\u001b[39m=\u001b[39moverrides)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:714\u001b[0m, in \u001b[0;36mload_config\u001b[0;34m(path, overrides, interpolate)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    713\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m config_path \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m config_path\u001b[39m.\u001b[39mis_file():\n\u001b[0;32m--> 714\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE053\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mconfig_path, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconfig file\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    715\u001b[0m     \u001b[39mreturn\u001b[39;00m config\u001b[39m.\u001b[39mfrom_disk(\n\u001b[1;32m    716\u001b[0m         config_path, overrides\u001b[39m=\u001b[39moverrides, interpolate\u001b[39m=\u001b[39minterpolate\n\u001b[1;32m    717\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: [E053] Could not read config file from /home/supriya/anaconda3/lib/python3.11/site-packages/en_core_web_sm/en_core_web_sm-2.3.1/config.cfg"
     ]
    }
   ],
   "source": [
    "\n",
    "data = ResumeParser(\"Supriya_Resume.pdf\").get_extracted_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/supriya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    " \n",
    "SKILLS_DB = [\n",
    "    'machine learning',\n",
    "    'data science',\n",
    "    'python',\n",
    "    'word',\n",
    "    'excel',\n",
    "    'english',\n",
    "    'react js', \n",
    "    'node.js', \n",
    "    'nest js',\n",
    "    'express', \n",
    "    'nest.js',  \n",
    "    'git', \n",
    "    'postgresql',\n",
    "    'firebase', \n",
    "    'redis', \n",
    "    'mongodb', \n",
    "    'docker', \n",
    "    'cloud services', \n",
    "    'chakra ui',\n",
    "]\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "def extract_skills(input_text):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    word_tokens = nltk.tokenize.word_tokenize(input_text)\n",
    " \n",
    "    # remove the stop words\n",
    "    filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
    " \n",
    "    # remove the punctuation\n",
    "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
    " \n",
    "    # generate bigrams and trigrams (such as artificial intelligence)\n",
    "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
    " \n",
    "    # we create a set to keep the results in.\n",
    "    found_skills = set()\n",
    " \n",
    "    # we search for each token in our skills database\n",
    "    for token in filtered_tokens:\n",
    "        if token.lower() in SKILLS_DB:\n",
    "            found_skills.add(token)\n",
    " \n",
    "    # we search for each bigram and trigram in our skills database\n",
    "    for ngram in bigrams_trigrams:\n",
    "        if ngram.lower() in SKILLS_DB:\n",
    "            found_skills.add(ngram)\n",
    " \n",
    "    return found_skills\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_n = extract_text_from_pdf('nimesh_CV.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_text_n = preprocess_text(text_n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skills summary github projects weather app  github  https   github com x  nimesh weather sorting visualizer  github  https   github com x  nimesh sorting visualizerrobinhood ai  github  https   github com x  nimesh robinhood_ai canteen management system  github  https   github com x  nimesh canteen management  system and more in my github nayabazar  kathmandu9869166973 https   github com x nimesh linkedin com in x nimesh   nimesh11 com npx nimesh7 gmail comcontact me at translate creative ui design to good quality code  integrated restful apis and graphql endpoints react js  diagonal technology  sankhamul   may 2022   sep 2022founder  wordpress administrator the rise online   jan 2020   2021work experience infodevelopers   sanepa   nov 2022   jun 2023node js developed the backend infrastructure for a cutting edge fintech application  nccs  national college of computer science   paknajol  kathmandu   neb  2  ashad 2074   2076prime college  khusibun  kathmandu   bca  bachelor in computer application  kartik 2076   currenteducation historyadaptable full stack developer with expertise in react js  node js  express  nest js  and git  proficient in postgresql  firebase  redis  mongodb  docker  cloud services  chakra ui  and react native  eager to learn and stay updated on emerging technologies personnel profilenimesh shrestha  full stack developer code himalaya   kupondole   jun 2023   currentnode js designing and implementing scalable  high performance applications using node js and related technologies  successfully developed distinct fintech applications for major tech giants of india front end sass  css  mysql  postgresql mongodb   firebase redisreact js  chakra ui node  express  nest js git  github  gitlabtypescript photoshop   illustration  react native designing and implementing apps using react  node js  react native  react js  node js  react native freelancer   aug 2022  currentjenkins  github actions\n"
     ]
    }
   ],
   "source": [
    "print(p_text_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chakra ui',\n",
       " 'cloud services',\n",
       " 'docker',\n",
       " 'express',\n",
       " 'firebase',\n",
       " 'git',\n",
       " 'mongodb',\n",
       " 'nest js',\n",
       " 'postgresql',\n",
       " 'react js',\n",
       " 'redis'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data science', 'machine learning', 'python'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_skills(p_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/supriya/anaconda3/lib/python3.11/site-packages/spacy/util.py:918: UserWarning: [W094] Model 'en_training' (0.0.0) specifies an under-constrained spaCy version requirement: >=2.1.4. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the \"spacy_version\" in your meta.json to a version range, with a lower and upper pin. For example: >=3.7.4,<3.8.0\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[E053] Could not read config file from /home/supriya/anaconda3/lib/python3.11/site-packages/pyresparser/config.cfg",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/supriya/Desktop/R-JD-matching/index.ipynb Cell 21\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Set spaCy language model as the default for Pyresparser\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# ResumeParser.DEFAULT_MODEL_PATH = nlp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Parse resume using Pyresparser\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m data \u001b[39m=\u001b[39m ResumeParser(\u001b[39m'\u001b[39m\u001b[39m/home/supriya/Desktop/R-JD-matching/Supriya_Resume.pdf\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mget_extracted_data()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyresparser/resume_parser.py:21\u001b[0m, in \u001b[0;36mResumeParser.__init__\u001b[0;34m(self, resume, skills_file, custom_regex)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     15\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     16\u001b[0m     resume,\n\u001b[1;32m     17\u001b[0m     skills_file\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m     custom_regex\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m     19\u001b[0m ):\n\u001b[1;32m     20\u001b[0m     nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m     custom_nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(\u001b[39m__file__\u001b[39m)))\n\u001b[1;32m     22\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__skills_file \u001b[39m=\u001b[39m skills_file\n\u001b[1;32m     23\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__custom_regex \u001b[39m=\u001b[39m custom_regex\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39mload_model(\n\u001b[1;32m     52\u001b[0m         name,\n\u001b[1;32m     53\u001b[0m         vocab\u001b[39m=\u001b[39mvocab,\n\u001b[1;32m     54\u001b[0m         disable\u001b[39m=\u001b[39mdisable,\n\u001b[1;32m     55\u001b[0m         enable\u001b[39m=\u001b[39menable,\n\u001b[1;32m     56\u001b[0m         exclude\u001b[39m=\u001b[39mexclude,\n\u001b[1;32m     57\u001b[0m         config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m     58\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:467\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[39mreturn\u001b[39;00m load_model_from_package(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[39mif\u001b[39;00m Path(name)\u001b[39m.\u001b[39mexists():  \u001b[39m# path to model data directory\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m         \u001b[39mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(name, \u001b[39m\"\u001b[39m\u001b[39mexists\u001b[39m\u001b[39m\"\u001b[39m):  \u001b[39m# Path or Path-like to model data\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:538\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    536\u001b[0m config_path \u001b[39m=\u001b[39m model_path \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mconfig.cfg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    537\u001b[0m overrides \u001b[39m=\u001b[39m dict_to_dot(config, for_overrides\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 538\u001b[0m config \u001b[39m=\u001b[39m load_config(config_path, overrides\u001b[39m=\u001b[39moverrides)\n\u001b[1;32m    539\u001b[0m nlp \u001b[39m=\u001b[39m load_model_from_config(\n\u001b[1;32m    540\u001b[0m     config,\n\u001b[1;32m    541\u001b[0m     vocab\u001b[39m=\u001b[39mvocab,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m     meta\u001b[39m=\u001b[39mmeta,\n\u001b[1;32m    546\u001b[0m )\n\u001b[1;32m    547\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\u001b[39m.\u001b[39mfrom_disk(model_path, exclude\u001b[39m=\u001b[39mexclude, overrides\u001b[39m=\u001b[39moverrides)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:714\u001b[0m, in \u001b[0;36mload_config\u001b[0;34m(path, overrides, interpolate)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    713\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m config_path \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m config_path\u001b[39m.\u001b[39mis_file():\n\u001b[0;32m--> 714\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE053\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mconfig_path, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconfig file\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    715\u001b[0m     \u001b[39mreturn\u001b[39;00m config\u001b[39m.\u001b[39mfrom_disk(\n\u001b[1;32m    716\u001b[0m         config_path, overrides\u001b[39m=\u001b[39moverrides, interpolate\u001b[39m=\u001b[39minterpolate\n\u001b[1;32m    717\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: [E053] Could not read config file from /home/supriya/anaconda3/lib/python3.11/site-packages/pyresparser/config.cfg"
     ]
    }
   ],
   "source": [
    "# Load spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Set spaCy language model as the default for Pyresparser\n",
    "# ResumeParser.DEFAULT_MODEL_PATH = nlp\n",
    "\n",
    "# Parse resume using Pyresparser\n",
    "data = ResumeParser('/home/supriya/Desktop/R-JD-matching/Supriya_Resume.pdf').get_extracted_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 'AffindaAPI' object has no attribute 'create_resume'\n"
     ]
    }
   ],
   "source": [
    "from affinda import AffindaAPI, TokenCredential\n",
    "\n",
    "# Define your Affinda API token credential\n",
    "credential = TokenCredential(token=\"aff_00307970892efee73b267c62144d310c41848670\")\n",
    "\n",
    "# Create an Affinda API client\n",
    "client = AffindaAPI(credential=credential)\n",
    "\n",
    "# Open the resume file in binary mode\n",
    "with open(\"/home/supriya/Desktop/R-JD-matching/Supriya_Resume.pdf\", \"rb\") as f:\n",
    "    try:\n",
    "        # Create a resume extraction task using the Affinda API\n",
    "        response = client.create_resume()\n",
    "        print(\"Resume extraction task created successfully!\")\n",
    "        print(\"Task ID:\", response['task_id'])\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/supriya/anaconda3/lib/python3.11/site-packages/spacy/util.py:918: UserWarning: [W094] Model 'en_training' (0.0.0) specifies an under-constrained spaCy version requirement: >=2.2.4. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the \"spacy_version\" in your meta.json to a version range, with a lower and upper pin. For example: >=3.7.4,<3.8.0\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[E053] Could not read config file from /home/supriya/anaconda3/lib/python3.11/site-packages/resume_parser/degree/model/config.cfg",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/supriya/Desktop/R-JD-matching/index.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mresume_parser\u001b[39;00m \u001b[39mimport\u001b[39;00m resumeparse\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#Y103sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data \u001b[39m=\u001b[39m resumeparse\u001b[39m.\u001b[39mread_file(\u001b[39m'\u001b[39m\u001b[39m/home/supriya/Desktop/R-JD-matching/Supriya_Resume.pdf\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/resume_parser/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mresume_parser\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mresumeparse\u001b[39;00m \u001b[39mimport\u001b[39;00m resumeparse\n\u001b[1;32m      3\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mresumeparse\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      5\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/resume_parser/resumeparse.py:51\u001b[0m\n\u001b[1;32m     47\u001b[0m base_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(\u001b[39m__file__\u001b[39m)\n\u001b[1;32m     50\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m custom_nlp2 \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_path,\u001b[39m\"\u001b[39m\u001b[39mdegree\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     52\u001b[0m custom_nlp3 \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_path,\u001b[39m\"\u001b[39m\u001b[39mcompany_working\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     54\u001b[0m \u001b[39m# initialize matcher with a vocab\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39mload_model(\n\u001b[1;32m     52\u001b[0m         name,\n\u001b[1;32m     53\u001b[0m         vocab\u001b[39m=\u001b[39mvocab,\n\u001b[1;32m     54\u001b[0m         disable\u001b[39m=\u001b[39mdisable,\n\u001b[1;32m     55\u001b[0m         enable\u001b[39m=\u001b[39menable,\n\u001b[1;32m     56\u001b[0m         exclude\u001b[39m=\u001b[39mexclude,\n\u001b[1;32m     57\u001b[0m         config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m     58\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:467\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[39mreturn\u001b[39;00m load_model_from_package(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[39mif\u001b[39;00m Path(name)\u001b[39m.\u001b[39mexists():  \u001b[39m# path to model data directory\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m         \u001b[39mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(name, \u001b[39m\"\u001b[39m\u001b[39mexists\u001b[39m\u001b[39m\"\u001b[39m):  \u001b[39m# Path or Path-like to model data\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:538\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    536\u001b[0m config_path \u001b[39m=\u001b[39m model_path \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mconfig.cfg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    537\u001b[0m overrides \u001b[39m=\u001b[39m dict_to_dot(config, for_overrides\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 538\u001b[0m config \u001b[39m=\u001b[39m load_config(config_path, overrides\u001b[39m=\u001b[39moverrides)\n\u001b[1;32m    539\u001b[0m nlp \u001b[39m=\u001b[39m load_model_from_config(\n\u001b[1;32m    540\u001b[0m     config,\n\u001b[1;32m    541\u001b[0m     vocab\u001b[39m=\u001b[39mvocab,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m     meta\u001b[39m=\u001b[39mmeta,\n\u001b[1;32m    546\u001b[0m )\n\u001b[1;32m    547\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\u001b[39m.\u001b[39mfrom_disk(model_path, exclude\u001b[39m=\u001b[39mexclude, overrides\u001b[39m=\u001b[39moverrides)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:714\u001b[0m, in \u001b[0;36mload_config\u001b[0;34m(path, overrides, interpolate)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    713\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m config_path \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m config_path\u001b[39m.\u001b[39mis_file():\n\u001b[0;32m--> 714\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE053\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mconfig_path, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconfig file\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    715\u001b[0m     \u001b[39mreturn\u001b[39;00m config\u001b[39m.\u001b[39mfrom_disk(\n\u001b[1;32m    716\u001b[0m         config_path, overrides\u001b[39m=\u001b[39moverrides, interpolate\u001b[39m=\u001b[39minterpolate\n\u001b[1;32m    717\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: [E053] Could not read config file from /home/supriya/anaconda3/lib/python3.11/site-packages/resume_parser/degree/model/config.cfg"
     ]
    }
   ],
   "source": [
    "from resume_parser import resumeparse\n",
    "\n",
    "data = resumeparse.read_file('/home/supriya/Desktop/R-JD-matching/Supriya_Resume.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keybert import KeyBERT\n",
    "# kw_model = KeyBERT()\n",
    "# keywords = kw_model.extract_keywords(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thapa', 'supriya', 'expertise', 'ai', 'projects']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_skills_keywords(p_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills_from_resume(resume_text):\n",
    "    preprocessed_text = preprocess_text(resume_text)\n",
    "\n",
    "    extracted_skills = extract_skills_keywords(preprocessed_text)\n",
    "\n",
    "    return extracted_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = extract_skills_from_resume(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thapa', 'supriya', 'expertise', 'ai', 'projects']\n"
     ]
    }
   ],
   "source": [
    "print(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Save results to a CSV file\n",
    "# results_df.to_csv(\"job_description_matching_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description_embeddings = get_embeddings(jd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_embeddings = get_embeddings(skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to calculate cosine similarity between two sets of embeddings\n",
    "def calculate_cosine_similarity(embeddings1, embeddings2):\n",
    "    return cosine_similarity(np.array(embeddings1), np.array(embeddings2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_score = calculate_cosine_similarity(job_description_embeddings, resume_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39816195 0.460676   0.4731068  0.41287562 0.44128025]]\n"
     ]
    }
   ],
   "source": [
    "print(similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39816195\n"
     ]
    }
   ],
   "source": [
    "print(similarity_score[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "  nlp = spacy.load('generated_model/model-best')\n",
    "  return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def function_1(file_path):\n",
    "  '''This function takes the pdf file number from the user and then choose the corresponding resumes \n",
    "  from the resume file and then give the result'''\n",
    "  text = extract_text_from_pdf(file_path)\n",
    "  # Preprocessing the text\n",
    "  text = preprocess_text(text)\n",
    "  # Load the model\n",
    "  nlp = load_model()\n",
    "  for doc in nlp.pipe([text], disable=[\"tagger\", \"parser\"]):\n",
    "    for ent in doc.ents:\n",
    "        text_name = re.sub('[^A-Za-z0-9]+', ' ', ent.text).strip()\n",
    "        print((text_name,ent.label_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_contact_number_from_resume(text):\n",
    "    contact_number = None\n",
    "\n",
    "    pattern = r\"\\b(?:\\+\\d{1,3}\\s?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3,4}[-.\\s]?\\d{4}\\b\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        contact_number = match.group()\n",
    "\n",
    "    return contact_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9817163439'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_contact_number_from_resume(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_from_resume(text):\n",
    "    email = None\n",
    "\n",
    "    pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        email = match.group()\n",
    "\n",
    "    return email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cherubbhujel@gmail.com'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_email_from_resume(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(resume_text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    # Define name patterns\n",
    "    patterns = [\n",
    "        [{'POS': 'PROPN'}, {'POS': 'PROPN'}],  # First name and Last name\n",
    "        [{'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}],  # First name, Middle name, and Last name\n",
    "        [{'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}]  # First name, Middle name, Middle name, and Last name\n",
    "        # Add more patterns as needed\n",
    "    ]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        matcher.add('NAME', patterns=[pattern])\n",
    "\n",
    "    doc = nlp(resume_text)\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        return span.text\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Supriya Thapa'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_name(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_skills_from_resume(text, skills_list):\n",
    "    skills = []\n",
    "\n",
    "    for skill in skills_list:\n",
    "        pattern = r\"\\b{}\\b\".format(re.escape(skill))\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            skills.append(skill)\n",
    "\n",
    "    return skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills: ['Python', 'Data Analysis', 'Machine Learning', 'Communication', 'Deep Learning', 'SQL']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "skills_list = ['Python', 'Data Analysis', 'Machine Learning', 'Communication', 'Project Management', 'Deep Learning', 'SQL', 'Tableau']\n",
    "\n",
    "extracted_skills = extract_skills_from_resume(text, skills_list)\n",
    "\n",
    "if extracted_skills:\n",
    "    print(\"Skills:\", extracted_skills)\n",
    "else:\n",
    "    print(\"No skills found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('/home/supriya/Desktop/R-JD-matching/dataset_entities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inova IT Helpdesk Technician Inova IT Helpdesk Technician Inova IT Helpdesk Technician Stafford VA Highly accomplished and experienced Communications Specialist with over 5 years of experience installation configuration and management of data network systems in both a stand-alone and client-server environment. Consistently complete projects with little to no supervision with superior results. Daily planned and executed the integration of multiple information systems in a network environment evaluated and resolved customer information system problems and utilized the required hardware upgrades and repaired to maintain mission capability.  A driven and versatile leader with a record of success in projects requiring an in-depth knowledge and solid experience working with complex communications systems. A quick study in emerging technology able to quickly assess and utilize the appropriate response to meet the specific needs of the business requirement at hand. A welcome addition to any team ready willing and able to function in any role necessary to ensure project success and on-time project delivery. Authorized to work in the US for any employer Work Experience Inova IT Helpdesk Technician Inova Healthcare Systems 2014 to 2015  Provide technical assistance and support for incoming queries and issues related to computer systems software and hardware.  Train computer users.  Respond to email messages for customers seeking help.  Ask questions to determine nature of problem.  Walk customer through problem-solving process.  Install modify and repair computer hardware and software.  Clean up computers.  Run diagnostic programs to resolve problems.  Resolve technical problems with Local Area Networks LAN Wide Area Networks WAN and other systems.  Install computer peripherals for users.  Follow up with customers to ensure issue has been resolved.  Gain feedback from customers about computer usage.  Run reports to determine malfunctions that continue to occur. Field Radio Technician Ericsson Communications and Clearwire 2013 to 2014  Installed repaired and maintained microwave radio and multiplex equipment both analog and digital and point to point communications systems.  Modified existing equipment to meet present needs.  Checked frequencies and solves interference problems.  Trained employees in the methods practices policies and procedures applicable to the work.  Emergency response to all Priority 1 and 2 outages that caused severe customer outages  Maintained Clearwire systems to get best coverage for day to day customers in the Clearwire network.  Install LTE equipment into all Clearwire stations to continue upgrading systems for better customer service.  Document photograph and upload system information into a new database after a completed conversion. Training Security and Administrative Clerk U.S. Marine Corps 2009 to 2011  Monitored verified and safeguarded personally identifiable information for a Battalion of over 3000 personnel  Assisted in compiling the annual training calendar for fiscal year 2011  Assisted high ranking military officials in keeping a typed chronological account of personnel and guests during the Marine Corps Half Marathon.  Consulted with military personnel to direct them to the appropriate policies and training personnel Information Security Specialist U.S. Marine Corps 2009 to 2009  Collected verified and configured user accounts for the Automated Message Handling System AMHS which replaced DMS  Taught over 100 individuals how to complete the requirements for access to AMHS  Administered AMHS for non-classified classified and secret personnel and messages  Liaison between the Information Security Section and Helpdesk Administrators to facilitate and improve application request response times  Provided day-to-day operation of the Electronic Key Management System EKMS as well as other duty areas related to Information Security INFOSEC such as Public Key Infrastructure PKI and FORTEZZA Card management  Implemented and monitored security measures for USMC communication information systems networks and advise the commander that systems and personnel adhere to established security standards and governmental requirements for security on these systems  Assisted in the development and execution of security policies plans and procedures design and implementation of data network security measures network intrusion detections and forensics information system security incident handling and certification of Marine Corps systems and networks Data Network Analyst U.S. Marine Corps 2008 to 2009  Assisted personnel in initial troubleshooting steps for Windows software and hardware  Configured printer/fax equipment aboard Marine Corps Base MCB Quantico to meet Department of Defense and Department of the Navy guidelines  Communicated with and assisted personnel of different ranks and computer literacy levels  Monitored several servers switches and routers aboard MCB Quantico.  Organized System Authorization Request Forms for the Defense Message System DMS to prepare for the new system  Utilized installed configured and instructed on the use of DOD Department of Defense SIPRNET SECRET Internet Protocol Router Network PKI Public Key Infrastructure CLO Cryptographic Logon and public key enablement of SIPRNET applications and web server Skills Networking 6 years Telecommunications 8 years Computer Skills Computer Skills 8 years Network Security 8 years Information Technology 8 years Information Security Information Security 8 years Microsoft Office 8 years Switches 8 years Routers 8 years Printers 8 years Problem Solving 8 years VOIP 3 years Engineering 3 years Military Service Branch United States Marine Corps Service Country United States Rank Pvt January 2008 to June 2011 Awards Letter of Accommodation 2010-01 Letter of Accommodation for installing and upgrading the Headquarters and Service Battalion mainframe including desktop printers and facsimile machines. Additional Information CORE COMPETENCIES Tactical Data Network  Personal Identifiable Information Security Workplace Safety  Quality Control Management  Defense Message Systems Training / Instruction  Requisition / Procurement Microsoft Word Microsoft Excel / PowerPoint / Access / Outlook / SharePoint\n"
     ]
    }
   ],
   "source": [
    "print(d['Text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Education</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Additional_Information</th>\n",
       "      <th>Software_Developer</th>\n",
       "      <th>Front_End_Developer</th>\n",
       "      <th>Network_Administrator</th>\n",
       "      <th>Web_Developer</th>\n",
       "      <th>Project_manager</th>\n",
       "      <th>Database_Administrator</th>\n",
       "      <th>Security_Analyst</th>\n",
       "      <th>Systems_Administrator</th>\n",
       "      <th>Python_Developer</th>\n",
       "      <th>Java_Developer</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inova IT Helpdesk Technician Inova IT Helpdesk...</td>\n",
       "      <td>Training Networking (6 years) VOIP (3 years)  ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inova IT Helpdesk Technician Inova Healthcare ...</td>\n",
       "      <td>CORE COMPETENCIES Tactical Data Network  Perso...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ServiceNow Administrator/ BA ServiceNow Admini...</td>\n",
       "      <td>NC SQL (6 years) Pharmaceutical Product Devel...</td>\n",
       "      <td>Masters in Computer Science Towson University ...</td>\n",
       "      <td>ServiceNow Administrator/ BA Sabre - Southlake...</td>\n",
       "      <td>Technical Skill Set  ITSM Tools ServiceNow Ber...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[8, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  Inova IT Helpdesk Technician Inova IT Helpdesk...   \n",
       "1  ServiceNow Administrator/ BA ServiceNow Admini...   \n",
       "\n",
       "                                              Skills  \\\n",
       "0  Training Networking (6 years) VOIP (3 years)  ...   \n",
       "1   NC SQL (6 years) Pharmaceutical Product Devel...   \n",
       "\n",
       "                                           Education  \\\n",
       "0                                                NaN   \n",
       "1  Masters in Computer Science Towson University ...   \n",
       "\n",
       "                                          Experience  \\\n",
       "0  Inova IT Helpdesk Technician Inova Healthcare ...   \n",
       "1  ServiceNow Administrator/ BA Sabre - Southlake...   \n",
       "\n",
       "                              Additional_Information  Software_Developer  \\\n",
       "0  CORE COMPETENCIES Tactical Data Network  Perso...                   0   \n",
       "1  Technical Skill Set  ITSM Tools ServiceNow Ber...                   1   \n",
       "\n",
       "   Front_End_Developer  Network_Administrator  Web_Developer  Project_manager  \\\n",
       "0                    0                      1              0                0   \n",
       "1                    0                      0              0                0   \n",
       "\n",
       "   Database_Administrator  Security_Analyst  Systems_Administrator  \\\n",
       "0                       0                 1                      0   \n",
       "1                       0                 0                      0   \n",
       "\n",
       "   Python_Developer  Java_Developer  Labels  \n",
       "0                 0               0  [2, 6]  \n",
       "1                 1               0  [8, 0]  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'Skills', 'Education', 'Experience', 'Additional_Information',\n",
       "       'Software_Developer', 'Front_End_Developer', 'Network_Administrator',\n",
       "       'Web_Developer', 'Project_manager', 'Database_Administrator',\n",
       "       'Security_Analyst', 'Systems_Administrator', 'Python_Developer',\n",
       "       'Java_Developer', 'Labels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'generated_model/model-best'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/supriya/Desktop/R-JD-matching/index.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m function_1(\u001b[39m'\u001b[39m\u001b[39m/home/supriya/Desktop/R-JD-matching/Supriya_Resume.pdf\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/supriya/Desktop/R-JD-matching/index.ipynb Cell 33\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X46sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m text \u001b[39m=\u001b[39m preprocess_text(text)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X46sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Load the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X46sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m nlp \u001b[39m=\u001b[39m load_model()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X46sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m nlp\u001b[39m.\u001b[39mpipe([text], disable\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mtagger\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mparser\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X46sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   \u001b[39mfor\u001b[39;00m ent \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39ments:\n",
      "\u001b[1;32m/home/supriya/Desktop/R-JD-matching/index.ipynb Cell 33\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mgenerated_model/model-best\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m nlp\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39mload_model(\n\u001b[1;32m     52\u001b[0m         name,\n\u001b[1;32m     53\u001b[0m         vocab\u001b[39m=\u001b[39mvocab,\n\u001b[1;32m     54\u001b[0m         disable\u001b[39m=\u001b[39mdisable,\n\u001b[1;32m     55\u001b[0m         enable\u001b[39m=\u001b[39menable,\n\u001b[1;32m     56\u001b[0m         exclude\u001b[39m=\u001b[39mexclude,\n\u001b[1;32m     57\u001b[0m         config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m     58\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    471\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'generated_model/model-best'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "function_1('/home/supriya/Desktop/R-JD-matching/Supriya_Resume.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E053] Could not read config file from /home/supriya/anaconda3/lib/python3.11/site-packages/en_core_web_sm/en_core_web_sm-2.3.1/config.cfg",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/supriya/Desktop/R-JD-matching/index.ipynb Cell 62\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#Y115sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#Y115sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39men_core_web_sm\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#Y115sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m nlp \u001b[39m=\u001b[39m en_core_web_sm\u001b[39m.\u001b[39mload()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#Y115sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m text \u001b[39m=\u001b[39m extract_text_from_pdf(\u001b[39m'\u001b[39m\u001b[39m/home/supriya/Desktop/R-JD-matching/Supriya_Resume.pdf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/supriya/Desktop/R-JD-matching/index.ipynb#Y115sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m x \u001b[39m=\u001b[39m nlp(text)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/en_core_web_sm/__init__.py:12\u001b[0m, in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides):\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_init_py(\u001b[39m__file__\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:682\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_path\u001b[39m.\u001b[39mexists():\n\u001b[1;32m    681\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE052\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mdata_path))\n\u001b[0;32m--> 682\u001b[0m \u001b[39mreturn\u001b[39;00m load_model_from_path(\n\u001b[1;32m    683\u001b[0m     data_path,\n\u001b[1;32m    684\u001b[0m     vocab\u001b[39m=\u001b[39mvocab,\n\u001b[1;32m    685\u001b[0m     meta\u001b[39m=\u001b[39mmeta,\n\u001b[1;32m    686\u001b[0m     disable\u001b[39m=\u001b[39mdisable,\n\u001b[1;32m    687\u001b[0m     enable\u001b[39m=\u001b[39menable,\n\u001b[1;32m    688\u001b[0m     exclude\u001b[39m=\u001b[39mexclude,\n\u001b[1;32m    689\u001b[0m     config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m    690\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:538\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    536\u001b[0m config_path \u001b[39m=\u001b[39m model_path \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mconfig.cfg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    537\u001b[0m overrides \u001b[39m=\u001b[39m dict_to_dot(config, for_overrides\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 538\u001b[0m config \u001b[39m=\u001b[39m load_config(config_path, overrides\u001b[39m=\u001b[39moverrides)\n\u001b[1;32m    539\u001b[0m nlp \u001b[39m=\u001b[39m load_model_from_config(\n\u001b[1;32m    540\u001b[0m     config,\n\u001b[1;32m    541\u001b[0m     vocab\u001b[39m=\u001b[39mvocab,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m     meta\u001b[39m=\u001b[39mmeta,\n\u001b[1;32m    546\u001b[0m )\n\u001b[1;32m    547\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\u001b[39m.\u001b[39mfrom_disk(model_path, exclude\u001b[39m=\u001b[39mexclude, overrides\u001b[39m=\u001b[39moverrides)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/util.py:714\u001b[0m, in \u001b[0;36mload_config\u001b[0;34m(path, overrides, interpolate)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    713\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m config_path \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m config_path\u001b[39m.\u001b[39mis_file():\n\u001b[0;32m--> 714\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE053\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mconfig_path, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconfig file\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    715\u001b[0m     \u001b[39mreturn\u001b[39;00m config\u001b[39m.\u001b[39mfrom_disk(\n\u001b[1;32m    716\u001b[0m         config_path, overrides\u001b[39m=\u001b[39moverrides, interpolate\u001b[39m=\u001b[39minterpolate\n\u001b[1;32m    717\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: [E053] Could not read config file from /home/supriya/anaconda3/lib/python3.11/site-packages/en_core_web_sm/en_core_web_sm-2.3.1/config.cfg"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "text = extract_text_from_pdf('/home/supriya/Desktop/R-JD-matching/Supriya_Resume.pdf')\n",
    "\n",
    "x = nlp(text)\n",
    "\n",
    "for i in x.ents:\n",
    "    print(\"Text: \", i.text, '\\tLabel:',i.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
